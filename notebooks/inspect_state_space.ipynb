{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from carps.analysis.gather_data import read_jsonl_content\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from carps.analysis.utils import setup_seaborn\n",
    "from omegaconf import OmegaConf\n",
    "from dacboenv.experiment.collect_incumbents import add_metadata_to_dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "setup_seaborn()\n",
    "\n",
    "log_fn = \"DACBOEnvLogs.jsonl\"\n",
    "rundirs = [\n",
    "    # \"../runs_eval/SMAC-AC--dacbo_Cepisode_length_scaled_plus_logregret_AWEI-cont_Ssmart_Repisode_finished_scaled_Ibbob2d_3seeds--seed1\",\n",
    "    # \"/scratch/hpc-prf-intexml/tklenke/experiment_runs/dacboenv_ppo_semi/runs/PPO-Perceptron-dacbo_Cepisode_length_scaled_plus_logregret_AWEI-cont_Ssmart_Repisode_finished_scaled_Ibbob2d_3seeds-1\",\n",
    "    # \"/scratch/hpc-prf-intexml/tklenke/experiment_runs/dacboenv_ppo_semi/runs/Random\",\n",
    "    \"../runs_statespace_icml\"\n",
    "]\n",
    "filenames = []\n",
    "for rundir in rundirs:\n",
    "    _fns = list(Path(rundir).glob(f\"**/{log_fn}\"))\n",
    "    filenames.extend(_fns)\n",
    "\n",
    "def load_obs(filenames: list[str]) -> tuple[pd.DataFrame, list[str]]:\n",
    "    observations = []\n",
    "    for rundir in tqdm(filenames):\n",
    "        rundir = Path(rundir)\n",
    "        cfg_fn = rundir.parent / \".hydra/config.yaml\"\n",
    "        cfg = OmegaConf.load(cfg_fn)\n",
    "        obs = read_jsonl_content(rundir)\n",
    "        obs_keys = list(obs.iloc[0][\"observation\"].keys())\n",
    "\n",
    "        expanded = obs[\"observation\"].apply(pd.Series)\n",
    "        expanded.columns = obs_keys\n",
    "        obs = obs.drop(columns=\"observation\").join(expanded)\n",
    "        policy_id = cfg.policy_id if hasattr(cfg, \"policy_id\") else rundir.parts[-8]\n",
    "        obs[\"policy_id\"] = policy_id\n",
    "        other_cols = [c for c in obs.columns if c not in obs_keys]\n",
    "        obs = obs.rename(columns={\"tsp\": \"tsd\", \"tsp_best\": \"tsd_best\"})\n",
    "        obs_keys = [c for c in obs.columns if c not in other_cols]\n",
    "        obs = add_metadata_to_dict(obs, cfg)\n",
    "        observations.append(obs)\n",
    "    observations = pd.concat(observations).reset_index(drop=True)\n",
    "    observations[\"task_id\"] = observations[\"task_id\"].map(lambda x: x.replace(\"bbob\", \"BBOB\"))\n",
    "    observations[\"task_id\"] = observations[\"task_id\"].map(lambda x: x[:-2] if x.startswith(\"BBOB\") else x)\n",
    "\n",
    "    return observations.dropna(), obs_keys\n",
    "\n",
    "def apply_pca_reduction(obs, obs_keys):\n",
    "    X = obs[obs_keys].to_numpy()\n",
    "    # X = X[~np.isnan(X).any(axis=1)]\n",
    "    pca = PCA(n_components=2)\n",
    "    X_pca = pca.fit_transform(X)\n",
    "    obs[\"X_pca\"] = list(X_pca)\n",
    "    expanded = obs[\"X_pca\"].apply(pd.Series)\n",
    "    expanded.columns = [f\"x_{i},pca\" for i in range(X_pca.shape[-1])]\n",
    "    return obs.drop(columns=\"X_pca\").join(expanded)\n",
    "\n",
    "\n",
    "print(len(filenames))\n",
    "obs, obs_keys = load_obs(filenames)\n",
    "obs.to_csv(\"obs.csv\", index=False)\n",
    "pd.Series(obs_keys).to_csv(\"obs_keys.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa44db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(obs), len(obs.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15897a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from carps.analysis.utils import get_color_palette, savefig, setup_seaborn\n",
    "\n",
    "\n",
    "setup_seaborn(font_scale=1.1)\n",
    "\n",
    "def plot_time_progression_quiver(\n",
    "    obs,\n",
    "    x_col=\"x_0,pca\",\n",
    "    y_col=\"x_1,pca\",\n",
    "    time_col=\"n_trials\",\n",
    "    policy_col=\"policy_id\",\n",
    "    figsize=(6, 4),\n",
    "    point_size=55,\n",
    "    arrow_width=0.01,\n",
    "    suffix: str | None = None,\n",
    "    legend_n_col: int = 1\n",
    "):\n",
    "    \"\"\"Plot time progression using arrows (quiver), per policy.\n",
    "\n",
    "    - Points show states\n",
    "    - Arrows point toward the next time step\n",
    "    - Start marker: hollow circle\n",
    "    - End marker: X\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    policies = obs[policy_col].unique()\n",
    "    policy_to_color = get_color_palette(optimizers=policies)\n",
    "\n",
    "    for (policy_id, seed), g in obs.groupby([policy_col, \"seed\"]):\n",
    "        # Sort by time within policy\n",
    "        g = g.sort_values(time_col)\n",
    "\n",
    "        x = g[x_col].values\n",
    "        y = g[y_col].values\n",
    "\n",
    "        if len(x) < 2:\n",
    "            continue\n",
    "\n",
    "        dx = np.diff(x)\n",
    "        dy = np.diff(y)\n",
    "\n",
    "        color = policy_to_color[policy_id]\n",
    "\n",
    "        label = policy_id\n",
    "\n",
    "        # Scatter points\n",
    "        ax.scatter(\n",
    "            x,\n",
    "            y,\n",
    "            s=point_size,\n",
    "            color=color,\n",
    "            alpha=0.8,\n",
    "            label=label,\n",
    "        )\n",
    "\n",
    "        # Quiver arrows (time direction)\n",
    "        ax.quiver(\n",
    "            x[:-1],\n",
    "            y[:-1],\n",
    "            dx,\n",
    "            dy,\n",
    "            angles=\"xy\",\n",
    "            scale_units=\"xy\",\n",
    "            scale=1,\n",
    "            width=arrow_width,\n",
    "            color=color,\n",
    "            alpha=0.5,\n",
    "        )\n",
    "\n",
    "        # Start marker\n",
    "        ax.scatter(\n",
    "            x[0],\n",
    "            y[0],\n",
    "            marker=\"o\",\n",
    "            s=point_size * 2.2,\n",
    "            facecolors=\"none\",\n",
    "            edgecolors=color,\n",
    "            linewidths=2,\n",
    "        )\n",
    "\n",
    "        # End marker\n",
    "        ax.scatter(\n",
    "            x[-1],\n",
    "            y[-1],\n",
    "            marker=\"X\",\n",
    "            s=point_size * 2.2,\n",
    "            color=color,\n",
    "            linewidths=2,\n",
    "        )\n",
    "    xlabel = x_col if x_col != \"x_0,pca\" else r\"$x_{0, \\mathrm{PCA}}$\"\n",
    "    ylabel = y_col if y_col != \"x_1,pca\" else r\"$x_{1, \\mathrm{PCA}}$\"\n",
    "    ax.set_xlabel(xlabel)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    ax.set_title(\"State Space (PCA(n=2))\")\n",
    "    suffix = suffix if suffix is not None else policy_col\n",
    "    ax.legend(title=None, bbox_to_anchor=(1.05, 1), ncol=legend_n_col)\n",
    "    fig.tight_layout()\n",
    "    savefig(fig=fig, filename=f\"figures/state_space/desiderata/{suffix}\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# for task_id, group in obs.groupby(\"task_id\"):\n",
    "#     plot_time_progression_quiver(group, task_id, arrow_width=0.004)\n",
    "#     # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bb5205",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"x_1,pca\" not in obs.columns:\n",
    "    obs = apply_pca_reduction(obs, obs_keys)\n",
    "\n",
    "\n",
    "seed = 2\n",
    "\n",
    "# (1): one optimizer (default), many functions (hue)\n",
    "group = obs[\n",
    "    (obs[\"optimizer_id\"] == \"DefaultPolicy\") & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\")\n",
    "]\n",
    "plot_time_progression_quiver(\n",
    "    group, policy_col=\"task_id\", suffix=\"diverse_tasks\", legend_n_col=2)\n",
    "\n",
    "group = obs[\n",
    "    (obs[\"optimizer_id\"] == \"DefaultPolicy\") & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/12\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/11\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/10\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/2\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/6\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/8\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/7\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/9\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/20\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/18\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/13\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/17\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/3\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/4\") & \\\n",
    "    (obs[\"task_id\"] != \"BBOB/2/15\") & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\")\n",
    "]\n",
    "plot_time_progression_quiver(group, policy_col=\"task_id\", suffix=\"diverse_tasks_reduced\")\n",
    "\n",
    "# (2): one task, many optimizers\n",
    "task_id = \"BBOB/2/20\"\n",
    "group = obs[\n",
    "    (obs[\"task_id\"] == task_id) & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\")\n",
    "    # (obs[\"optimizer_id\"] == \"Jump-0.5\")\n",
    "]\n",
    "plot_time_progression_quiver(group)\n",
    "\n",
    "# (3): one optimizer (default), two action spaces\n",
    "task_id = \"BBOB/2/20\"\n",
    "group = obs[\n",
    "    (obs[\"task_id\"] == task_id) & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    # (obs[\"action_space_id\"] == \"\") & \\\n",
    "    (obs[\"optimizer_id\"] == \"Random\")\n",
    "]\n",
    "plot_time_progression_quiver(group, policy_col=\"action_space_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793ed131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from carps.analysis.utils import setup_seaborn, get_marker_palette, savefig\n",
    "\n",
    "setup_seaborn(font_scale=1.1)\n",
    "\n",
    "# (3): single S over time over bbob 20, jump\n",
    "task_id = \"bbob/2/20/0\"\n",
    "group = obs[\n",
    "    # (obs[\"task_id\"] == task_id) & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\") & \\\n",
    "    (obs[\"optimizer_id\"] == \"Jump-0.5\")\n",
    "]\n",
    "keys_progress = [\n",
    "    \"trials_passed\",\n",
    "    \"trials_left\",\n",
    "    \"budget_percentage\"\n",
    "]\n",
    "keys_model = [\n",
    "    \"ubr\",\n",
    "    \"ubr_difference\",\n",
    "    \"acq_value_EI\",\n",
    "    \"acq_value_PI\",\n",
    "]\n",
    "keys_xhist = [\n",
    "    \"tsd\",\n",
    "    \"tsd_best\",\n",
    "    \"knn_entropy\",\n",
    "    \"knn_entropy_best\",\n",
    "    \"knn_difference\"\n",
    "]\n",
    "keys_yhist = [\n",
    "    \"incumbent_changes\",\n",
    "    \"inc_improvement_scaled\",\n",
    "    \"y_mean\",\n",
    "    \"y_mean_best\",\n",
    "    \"y_std\",\n",
    "    \"y_std_best\",\n",
    "    \"y_skewness\",\n",
    "    \"y_skewness_best\",\n",
    "    \"y_kurtosis\",\n",
    "    \"y_kurtosis_best\",\n",
    "    # \"y_variability\",\n",
    "    # \"y_variability_best\",\n",
    "]\n",
    "keys_gp = [\n",
    " \"gp_hp_k1__k1__constant_value0_observation\",\n",
    " \"gp_hp_k1__k2__length_scale0_observation\",\n",
    " \"gp_hp_k1__k2__length_scale1_observation\",\n",
    " \"gp_hp_k2__noise_level0_observation\",\n",
    "]\n",
    "keys_search_space = [\n",
    "    \"searchspace_dim\",\n",
    "    \"continuous_hps\",\n",
    "    \"categorical_hps\",\n",
    "    \"ordinal_hps\",\n",
    "    \"int_hps\",\n",
    "    \"has_categorical_hps\"\n",
    "]\n",
    "# assert len(obs_keys) == len(keys_progress + keys_search_space + keys_model + keys_xhist + keys_yhist + keys_gp)\n",
    "\n",
    "def plot_states(group, keys, title, identifier, cols_max=4):\n",
    "    ncols = min(cols_max, len(keys))\n",
    "    nrows = math.ceil(len(keys) / ncols)\n",
    "    axwidth = 2\n",
    "    axheight = 2.5\n",
    "    legendspace = 2\n",
    "    fig = plt.figure(figsize=(axwidth * ncols, axheight * nrows + legendspace))\n",
    "    axes = fig.subplots(ncols=ncols, nrows=nrows)\n",
    "    task_ids = list(group[\"task_id\"].unique())\n",
    "    palette = get_color_palette(optimizers=task_ids)\n",
    "    marker_palette = get_marker_palette(optimizers=task_ids)\n",
    "    for i, key in enumerate(keys):\n",
    "        _key = key\n",
    "        if key in [\"ubr\", \"y_mean\", \"y_mean_best\", \"y_std\", \"y_std_best\"]:\n",
    "            _key = key + \" (norm)\"\n",
    "            group[_key] = group.groupby(\"task_id\")[key].transform(lambda x: x / x.min() / (x.max() - x.min()))\n",
    "        ax = axes.flat[i]\n",
    "        ax = sns.lineplot(\n",
    "            data=group,\n",
    "            x=\"n_trials\",\n",
    "            y=_key,\n",
    "            hue=\"task_id\",\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            linewidth=2,\n",
    "            style=\"task_id\",\n",
    "            dashes=False,\n",
    "            markers=marker_palette,\n",
    "            markevery=20\n",
    "        )\n",
    "        ax.legend().remove()\n",
    "\n",
    "    legend = ax.legend()\n",
    "    fig.suptitle(title)\n",
    "    fig.legend(\n",
    "        handles=legend.legend_handles,\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, -0.4),\n",
    "        ncols=4,\n",
    "    )\n",
    "    legend.remove()\n",
    "    fig.tight_layout()\n",
    "    savefig(fig=fig, filename=f\"figures/state_space/single/{identifier}\")\n",
    "    plt.show()\n",
    "\n",
    "cols_max = 6\n",
    "print(group.columns)\n",
    "plot_states(group, keys_progress, \"Progress\", \"progress\", cols_max=cols_max)\n",
    "plot_states(group, keys_model, \"Model\", \"model\", cols_max=cols_max)\n",
    "plot_states(group, keys_search_space, \"Search Space\", \"search_space\", cols_max=cols_max)\n",
    "plot_states(group, keys_xhist, \"History ($\\\\Lambda$)\", \"history_x\", cols_max=cols_max)\n",
    "plot_states(group, keys_yhist, \"History ($\\\\mathcal{O}$)\", \"history_y\", cols_max=cols_max)\n",
    "plot_states(group, keys_gp, \"GP HPs\", \"gp_hps\", cols_max=cols_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59900c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from carps.analysis.utils import setup_seaborn, savefig\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "obs = pd.read_csv(\"obs.csv\")\n",
    "\n",
    "setup_seaborn(font_scale=1.1)\n",
    "\n",
    "task_id = \"BBOB/2/8\"\n",
    "seed = 3\n",
    "group = obs[\n",
    "    # (obs[\"task_id\"] == task_id) & \\\n",
    "    (obs[\"task_id\"].isin([\"BBOB/2/1\", \"BBOB/2/8\", \"BBOB/2/17\", \"BBOB/2/20\"])) & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\") & \\\n",
    "    (obs[\"optimizer_id\"] == \"DefaultPolicy\")\n",
    "]\n",
    "group[\"task_id\"] = group[\"task_id\"].map(lambda x: f\"BBOB-fid {x.split('/')[2]}\")\n",
    "group = group[group[\"task_id\"] == \"BBOB-fid 8\"]\n",
    "\n",
    "\n",
    "group = pd.read_parquet(\"sawei_bbob2d_envlogs.parquet\")\n",
    "group = group[group[\"task_id\"] == \"bbob/2/8/0\"]\n",
    "group = group[group[\"seed\"] == 3]\n",
    "group[\"alpha\"] = group[\"action\"]\n",
    "group[\"source\"] = \"SAWEI\"\n",
    "\n",
    "\n",
    "# print(obs.columns)\n",
    "delta_alpha = 0.1\n",
    "\n",
    "k = 100\n",
    "\n",
    "res = []\n",
    "for task_id, gdf in group.groupby(\"task_id\"):\n",
    "    previous_alpha = 0.5\n",
    "    # ubr = gdf[\"ubr\"].to_numpy()\n",
    "    # ubr_diff = np.diff(ubr)\n",
    "    ubr_smoothed_gradient = gdf[\"ubr_smoothed_gradient\"].to_numpy()\n",
    "    n_trials_min = gdf[\"n_trials\"].min()\n",
    "    v_ei = gdf[\"acq_value_WEI_explore\"].to_numpy()\n",
    "    v_pi = gdf[\"acq_value_PI\"].to_numpy()\n",
    "    # ubr_max = ubr.max()\n",
    "    # ubr_min = ubr.min()\n",
    "    # ubr_norm = (ubr - ubr_min) / (ubr_max - ubr_min)\n",
    "    # ubr_norm = ubr_norm[1:]\n",
    "    ubr_smoothed_gradient_max = ubr_smoothed_gradient.max()\n",
    "    ubr_smoothed_gradient_min = ubr_smoothed_gradient.min()\n",
    "    ubr_smoothed_gradient_norm = (ubr_smoothed_gradient - ubr_smoothed_gradient_min) / \\\n",
    "        (ubr_smoothed_gradient_max - ubr_smoothed_gradient_min)\n",
    "\n",
    "    alphas = []\n",
    "    adjustments = []\n",
    "    for step in range(len(ubr_smoothed_gradient)):\n",
    "        sigma_r = np.std(ubr_smoothed_gradient[:step])\n",
    "        if np.isnan(sigma_r):\n",
    "            sigma_r = 1\n",
    "        r = ubr_smoothed_gradient[step]\n",
    "        _v_ei = v_ei[step]\n",
    "        _v_pi = v_pi[step]\n",
    "\n",
    "        adjustment = delta_alpha * np.tanh(k * (-_v_pi + _v_ei)) * np.exp(-r ** 2 / sigma_r ** 2)\n",
    "        alpha = previous_alpha + adjustment\n",
    "\n",
    "        alpha_clipped = max(0, min(1, alpha))\n",
    "        alphas.append(alpha_clipped)\n",
    "        previous_alpha = alpha_clipped\n",
    "        adjustments.append(adjustment)\n",
    "    res.append(pd.DataFrame({\n",
    "        \"step\": np.arange(0, len(alphas)),\n",
    "        \"n_trials\": np.arange(0, len(alphas)) + n_trials_min,\n",
    "        \"alpha\": alphas,\n",
    "        \"task_id\": task_id,\n",
    "        \"seed\": seed,\n",
    "        \"adjustment\": adjustments,\n",
    "        # \"ubr_norm\": ubr_norm,\n",
    "        # \"acq_value_WEI_explore\": v_ei,\n",
    "        # \"acq_value_PI\": v_pi,\n",
    "        # \"ubr_smoothed_gradient\": ubr_smoothed_gradient,\n",
    "        \"source\": \"approximation\"\n",
    "    }))\n",
    "res = pd.concat(res).reset_index(drop=True)\n",
    "res = pd.concat([group, res]).reset_index(drop=True)\n",
    "# res = group\n",
    "\n",
    "fig = plt.figure(figsize=(10,3))\n",
    "axes = fig.subplots(nrows=1, ncols=4, sharex=True, sharey=False)\n",
    "\n",
    "# ax = axes[0]\n",
    "# ax = sns.lineplot(data=res, x=\"step\", y=\"ubr_norm\", hue=\"task_id\", ax = ax, linewidth=2)\n",
    "# ax.set_xlabel(\"Step\")\n",
    "# ax.set_ylabel(\"UBR (Normalized)\")\n",
    "# ax.legend(title=None).remove()\n",
    "\n",
    "ax = axes[0]\n",
    "ax = sns.lineplot(data=res, x=\"n_trials\", y=\"ubr_smoothed_gradient\", hue=\"source\", ax = ax, linewidth=2)\n",
    "ax.set_xlabel(\"$n_\\\\mathrm{trials}$\")\n",
    "ax.set_ylabel(\"$\\\\nabla\\\\mathrm{UBR}$\")\n",
    "ax.legend(title=None).remove()\n",
    "\n",
    "ax = axes[1]\n",
    "ax = sns.lineplot(data=res, x=\"n_trials\", y=\"acq_value_WEI_explore\", hue=\"source\", ax = ax, linewidth=2)\n",
    "ax.set_xlabel(\"$n_\\\\mathrm{trials}$\")\n",
    "ax.set_ylabel(\"Acq Value of WEI\\n(Explore)\")\n",
    "ax.legend(title=None).remove()\n",
    "\n",
    "ax = axes[2]\n",
    "ax = sns.lineplot(data=res, x=\"n_trials\", y=\"acq_value_PI\", hue=\"source\", ax = ax, linewidth=2)\n",
    "ax.set_xlabel(\"$n_\\\\mathrm{trials}$\")\n",
    "ax.set_ylabel(\"Acq Value of PI\")\n",
    "ax.legend(title=None).remove()\n",
    "\n",
    "ax = axes[3]\n",
    "ax = sns.lineplot(data=res, x=\"n_trials\", y=\"alpha\", hue=\"source\", ax = ax, linewidth=2)\n",
    "ax.set_xlabel(\"$n_\\\\mathrm{trials}$\")\n",
    "ax.set_ylabel(\"$\\\\alpha$\")\n",
    "ax.legend(title=None).remove()\n",
    "\n",
    "# ax = axes[2]\n",
    "# ax = sns.lineplot(data=res, x=\"step\", y=\"adjustment\", hue=\"task_id\", ax =ax, linewidth=2)\n",
    "# ax.set_xlabel(\"Step\")\n",
    "# ax.set_ylabel(\"$\\\\Delta\\\\alpha$\")\n",
    "\n",
    "ax.legend(title=None, bbox_to_anchor=(1.05, 1))\n",
    "fig.tight_layout()\n",
    "savefig(fig=fig, filename=\"figures/dacbo/analytical_sawei\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a412cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AlphaRuleNetDynamicR(nn.Module):\n",
    "    def __init__(self, delta_alpha=0.1, k=10.0):\n",
    "        super().__init__()\n",
    "        self.delta_alpha = delta_alpha\n",
    "        self.k = k\n",
    "\n",
    "        # 5 inputs now (R_scale is dynamic)\n",
    "        self.fc1 = nn.Linear(5, 8)\n",
    "        self.fc2 = nn.Linear(8, 1)\n",
    "\n",
    "        # Preinitialize output bias to 0\n",
    "        nn.init.constant_(self.fc2.bias, 0.0)\n",
    "\n",
    "        # Preinitialize hidden layer weights roughly (as before)\n",
    "        self.fc1.weight.data.zero_()\n",
    "        self.fc1.bias.data.zero_()\n",
    "        # Neurons 0-3 approximate tanh(k*(v_PI - v_EI))\n",
    "        self.fc1.weight.data[0,1] = k\n",
    "        self.fc1.weight.data[1,2] = -k\n",
    "        self.fc1.weight.data[2,1] = 0.5*k\n",
    "        self.fc1.weight.data[2,2] = -0.5*k\n",
    "        self.fc1.weight.data[3,1] = 0.5*k\n",
    "        self.fc1.weight.data[3,2] = -0.5*k\n",
    "        # Neurons 4-7 approximate Gaussian gate using R / R_scale\n",
    "        self.fc1.weight.data[4,0] = -1.0  # R coefficient\n",
    "        self.fc1.weight.data[4,4] = 1.0   # R_scale coefficient\n",
    "        self.fc1.weight.data[5,0] = 1.0\n",
    "        self.fc1.weight.data[5,4] = -1.0\n",
    "        self.fc1.weight.data[6,0] = -0.5\n",
    "        self.fc1.weight.data[6,4] = 0.5\n",
    "        self.fc1.weight.data[7,0] = 0.5\n",
    "        self.fc1.weight.data[7,4] = -0.5\n",
    "\n",
    "        # Output weights\n",
    "        self.fc2.weight.data.fill_(delta_alpha * 0.125)\n",
    "\n",
    "    def forward(self, x):\n",
    "        R = x[:,0:1]\n",
    "        v_PI = x[:,1:2]\n",
    "        v_EI = x[:,2:3]\n",
    "        alpha_prev = x[:,3:4]\n",
    "        R_scale = x[:,4:5]\n",
    "\n",
    "        # Hidden layer\n",
    "        h = torch.tanh(self.fc1(x))\n",
    "\n",
    "        # Linear output\n",
    "        delta_alpha_out = self.fc2(h)\n",
    "\n",
    "        # Update alpha\n",
    "        alpha_new = alpha_prev + delta_alpha_out\n",
    "        alpha_new = torch.clamp(alpha_new, 0.0, 1.0)\n",
    "        return alpha_new\n",
    "\n",
    "net = AlphaRuleNetDynamicR()\n",
    "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
    "print(\"Number of adjustable (trainable) parameters:\", num_params)\n",
    "\n",
    "task_id = \"bbob/2/8/0\"\n",
    "seed = 3\n",
    "group = obs[\n",
    "    # (obs[\"task_id\"] == task_id) & \\\n",
    "    (obs[\"seed\"] == seed) & \\\n",
    "    (obs[\"action_space_id\"] == \"WEI-cont\") & \\\n",
    "    (obs[\"optimizer_id\"] == \"Jump-0.5\")\n",
    "]\n",
    "\n",
    "\n",
    "delta_alpha = 0.1\n",
    "previous_alpha = 0.5\n",
    "k = 100\n",
    "\n",
    "res = []\n",
    "for task_id, gdf in group.groupby(\"task_id\"):\n",
    "    ubr = gdf[\"ubr\"].to_numpy()\n",
    "    ubr_diff = np.diff(ubr)\n",
    "    v_ei = gdf[\"acq_value_EI\"].to_numpy()\n",
    "    v_pi = gdf[\"acq_value_PI\"].to_numpy()\n",
    "\n",
    "    alphas = []\n",
    "    net = AlphaRuleNetDynamicR()\n",
    "    for step in range(len(ubr_diff)):\n",
    "        sigma_r = np.std(ubr_diff[:step])\n",
    "        if np.isnan(sigma_r):\n",
    "            sigma_r = 1\n",
    "        r = ubr_diff[step]\n",
    "        _v_ei = v_ei[step]\n",
    "        _v_pi = v_pi[step]\n",
    "\n",
    "        x = torch.tensor([[r, _v_pi, _v_ei, previous_alpha, sigma_r]], dtype=torch.float32)  # R, v_PI, v_EI, alpha_prev, R_scale\n",
    "        alpha = float(torch.squeeze(net(x).detach()))\n",
    "        previous_alpha = alpha\n",
    "        alphas.append(alpha)\n",
    "    res.append(pd.DataFrame({\n",
    "        \"step\": np.arange(0, len(alphas)),\n",
    "        \"alpha\": alphas,\n",
    "        \"task_id\": task_id,\n",
    "        \"seed\": seed\n",
    "    }))\n",
    "res = pd.concat(res).reset_index(drop=True)\n",
    "\n",
    "sns.lineplot(data=res, x=\"step\", y=\"alpha\", hue=\"task_id\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314f248e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_state(group, keys, title, cols_max=4):\n",
    "    ncols = min(cols_max, len(keys))\n",
    "    nrows = math.ceil(len(keys) / ncols)\n",
    "    axwidth = 6\n",
    "    axheight = 4\n",
    "    legendspace = 2\n",
    "    fig = plt.figure(figsize=(axwidth * ncols, axheight * nrows + legendspace))\n",
    "    axes = fig.subplots(ncols=ncols, nrows=nrows)\n",
    "    task_ids = list(group[\"task_id\"].unique())\n",
    "    palette = get_color_palette(optimizers=task_ids)\n",
    "    marker_palette = get_marker_palette(optimizers=task_ids)\n",
    "    for i, key in enumerate(keys):\n",
    "        if len(keys) == 1:\n",
    "            ax = axes\n",
    "        else:\n",
    "            ax = axes.flat[i]\n",
    "        ax = sns.lineplot(\n",
    "            data=group,\n",
    "            x=\"n_trials\",\n",
    "            y=key,\n",
    "            hue=\"task_id\",\n",
    "            palette=palette,\n",
    "            ax=ax,\n",
    "            linewidth=2,\n",
    "            style=\"task_id\",\n",
    "            dashes=False,\n",
    "            markers=marker_palette,\n",
    "            markevery=20\n",
    "        )\n",
    "        ax.legend().remove()\n",
    "\n",
    "    legend = ax.legend()\n",
    "    fig.suptitle(title)\n",
    "    fig.legend(\n",
    "        handles=legend.legend_handles,\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0.5, -0.4),\n",
    "        ncols=4,\n",
    "    )\n",
    "    legend.remove()\n",
    "    fig.tight_layout()\n",
    "    # savefig(fig=fig, filename=f\"figures/state_space/single/{title}\") \n",
    "    plt.show()\n",
    "\n",
    "plot_state(group[\n",
    "    group[\"task_id\"].isin([\"bbob/2/1/0\", \"bbob/2/20/0\"])\n",
    "], keys=[\"acq_value_PI\"], title=\"acq_value_PI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49d2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if \"x_1,pca\" not in obs.columns:\n",
    "    obs = apply_pca_reduction(obs, obs_keys)\n",
    "\n",
    "for task_id, group in obs.groupby(\"task_id\"):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    ax = sns.scatterplot(\n",
    "        data=group,\n",
    "        x=\"x_0,pca\",\n",
    "        y=\"x_1,pca\",\n",
    "        hue=\"policy_id\",\n",
    "        style=\"seed\"\n",
    "    )\n",
    "\n",
    "    ax.set_title(f\"State Space (PCA(n=2))\\n{task_id}\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3f216f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
