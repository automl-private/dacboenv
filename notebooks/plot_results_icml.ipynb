{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379ac9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from carps.analysis.gather_data import filelogs_to_df, get_interpolated_performance_df, normalize_logs, normalize\n",
    "from carps.analysis.generate_report import load_results\n",
    "from carps.analysis.run_autorank import (\n",
    "    calc_critical_difference,\n",
    "    cd_evaluation,\n",
    "    get_df_crit,\n",
    ")\n",
    "from carps.analysis.utils import (\n",
    "    colorblind_palette,\n",
    "    filter_only_final_performance,\n",
    "    get_color_palette,\n",
    "    get_marker_palette,\n",
    "    savefig,\n",
    "    setup_seaborn,\n",
    ")\n",
    "from dacboenv.experiment.analysis.utils import RWBM, create_yaml_string, postprocess_benchmarks, sort_df_by_mean\n",
    "from dacboenv.experiment.collect_incumbents import add_metadata_to_dict\n",
    "from matplotlib.lines import Line2D\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "df_final_processed_fn = \"eval_final_perf.parquet\"\n",
    "logsprocessed_fn = \"logs_processed.parquet\"\n",
    "logsprocessed_cfg_fn = \"logs_processed_cfg.parquet\"\n",
    "key_performance = \"log_regret\"\n",
    "result_dir = \"../results_icml\"\n",
    "metabo_fn = \"/scratch/anonymous/tanonymous/repos/MetaBO/merged_rewards_total.csv\"\n",
    "\n",
    "def fix_benchmark_id(logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    def _fix_benchmark_id(row: pd.Series) -> str:\n",
    "        if row[\"task_id\"].startswith(\"bbob/2\"):\n",
    "            return \"BBOB-2d\"\n",
    "        if row[\"task_id\"].startswith(\"bbob/8\"):\n",
    "            return \"BBOB-8d\"\n",
    "        return row[\"benchmark_id\"]\n",
    "    logs[\"benchmark_id\"] = logs.apply(_fix_benchmark_id, axis=\"columns\")\n",
    "    return logs\n",
    "\n",
    "def postprocess_logs(logs: pd.DataFrame, logs_cfg: pd.DataFrame) -> pd.DataFrame:\n",
    "    print(\"Postprocess benchmarks...\")\n",
    "    logs = postprocess_benchmarks(logs, logs_cfg)\n",
    "    print(\"Fix benchmark id...\")\n",
    "    logs = fix_benchmark_id(logs)\n",
    "    print(\"Done postprocessing logs!\")\n",
    "    return logs\n",
    "\n",
    "def load_logs(result_dir: str) -> tuple[pd.DataFrame,pd.DataFrame]:\n",
    "    logs = load_results(Path(result_dir) / \"logs.parquet\", normalize=True)\n",
    "    logs_cfg = pd.read_parquet(Path(result_dir) / \"logs_cfg.parquet\")\n",
    "    logs = postprocess_logs(logs, logs_cfg)\n",
    "    return logs, logs_cfg\n",
    "\n",
    "def hatch_for_optimizer(opt):\n",
    "    if opt == \"Static\":\n",
    "        return \"-\"\n",
    "    if opt == \"SAWEI\":\n",
    "        return \"|\"\n",
    "    if opt.startswith(\"MetaBO\"):\n",
    "        return \"o\"\n",
    "    if opt.endswith(\"vbs\"):\n",
    "        return \"xx\"\n",
    "    if opt.endswith(\"mean\"):\n",
    "        return \"\\\\\\\\\\\\\"\n",
    "    if opt.endswith(\"--seed\") or \"--seed\" in opt:\n",
    "        return \"\"\n",
    "    if opt in {\"DefaultPolicy\", \"SAWEI-P\", \"Random\"}:\n",
    "        return \"..\"\n",
    "    return \"\"\n",
    "\n",
    "# Load and merge\n",
    "skip_processing = True\n",
    "if not (Path(result_dir) / logsprocessed_fn).is_file():\n",
    "    skip_processing = False\n",
    "    print(f\"{Path(result_dir) / logsprocessed_fn} does not exist. Load and process.\")\n",
    "\n",
    "if not skip_processing:\n",
    "    logs, logs_cfg = load_logs(result_dir=result_dir)\n",
    "    logs.to_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "    logs_cfg.to_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "    df_final = filter_only_final_performance(logs)\n",
    "    df_final.to_parquet(Path(result_dir) / df_final_processed_fn, index=False)\n",
    "\n",
    "\n",
    "def fix_log_regret_inf(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    finite_vals = df.loc[\n",
    "        np.isfinite(df[\"log_regret\"]),\n",
    "        \"log_regret\"\n",
    "    ]\n",
    "    floor = finite_vals.min() - 0.5\n",
    "    df[\"solved\"] = df[\"log_regret\"].eq(-np.inf)\n",
    "    df[\"log_regret\"] = df[\"log_regret\"].replace(-np.inf, floor)\n",
    "    return df\n",
    "\n",
    "def filter_experiments(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    optimizer_prefixes = [\n",
    "        # \"PPO-RNN-norm--dacbo_Cepisode_length_scaled_plus_logregret_AWEI-cont_Ssawei_Repisode_finished_scaled-DefaultAction_Ibbob2d_3seeds\",\n",
    "        \"PPO-MLP--dacbo_Csymlogregret_AWEI-skip_Ssawei_Rsymlogregret-SAWEI-P_Ibbob2d_fid8_3seeds\",\n",
    "        \"PPO-MLP--dacbo_Csymlogregret_AWEI-skip_Ssawei_Rsymlogregret-SAWEI-P_Ibbob2d_3seeds\",\n",
    "        # \"PPO\",\n",
    "        \"DefaultPolicy\",\n",
    "        \"Random\",\n",
    "        \"SAWEI-P\",\n",
    "        \"MetaBO-BBOB-8-2D-v0\",\n",
    "        \"MetaBO-BBOB-2D-v0\",\n",
    "    ]\n",
    "    df.loc[df[\"optimizer_id\"] == \"NoOpPolicy\", \"optimizer_id\"] = \"DefaultPolicy\"\n",
    "    df = df[df[\"optimizer_id\"].map(lambda x: any(x.startswith(opt_id) for opt_id in optimizer_prefixes))].copy()\n",
    "    # Rename MetaBO\n",
    "    df[\"optimizer_id\"] = df[\"optimizer_id\"].map(lambda x: \"MetaBO-Ros\" if \"MetaBO-BBOB-8-2D\" in x else x)\n",
    "    df[\"optimizer_id\"] = df[\"optimizer_id\"].map(lambda x: \"MetaBO-BBOB\" if \"MetaBO-BBOB-2D\" in x else x)\n",
    "    # Rename PPO\n",
    "    df[\"optimizer_id\"] = df[\"optimizer_id\"].map(lambda x: \"PPO-Ros--\" + x.split(\"--\")[-1] if \"fid8\" in x else x)\n",
    "    df[\"optimizer_id\"] = df[\"optimizer_id\"].map(lambda x: \"PPO-BBOB--\" + x.split(\"--\")[-1] if \"bbob2d_3s\" in x else x)\n",
    "    df.loc[df[\"optimizer_id\"] == \"SAWEI-P\", \"optimizer_id\"] = \"SAWEI\"\n",
    "    df.loc[df[\"optimizer_id\"] == \"DefaultPolicy\", \"optimizer_id\"] = \"Static\"\n",
    "    print(df[\"optimizer_id\"].unique())\n",
    "    return df\n",
    "\n",
    "def load_df_final() -> pd.DataFrame:\n",
    "    df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "    df_metabo = pd.read_csv(metabo_fn)\n",
    "    df_metabo[\"n_trials_norm\"] = df_metabo.groupby(\"task_id\")[\"n_trials\"].transform(normalize)\n",
    "    df_metabo = filter_only_final_performance(df_metabo, key_performance=\"log_regret\")\n",
    "    df_metabo = fix_benchmark_id(df_metabo)\n",
    "    df_final = pd.concat([df_final, df_metabo])\n",
    "    df_final = filter_experiments(df_final)\n",
    "    df_final = fix_log_regret_inf(df_final)\n",
    "\n",
    "    # Reduce PPO name\n",
    "    df_final_ppo = df_final[df_final[\"optimizer_id\"].str.startswith(\"PPO\")].copy()\n",
    "    df_final_ppo[\"outer_seed\"] = df_final_ppo[\"optimizer_id\"].map(lambda x: int(x.split(\"--\")[-1].replace(\"seed\", \"\")))\n",
    "\n",
    "    # Average over outer seeds\n",
    "    df_final_ppo_mean = df_final_ppo.groupby([\"benchmark_id\", \"optimizer_id\", \"task_id\", \"seed\"])[\"log_regret\"].mean().reset_index().copy()\n",
    "    df_final_ppo_mean[\"optimizer_id\"] = df_final_ppo_mean[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1]) + \"--mean\")\n",
    "\n",
    "    # Calculate VBS over outer seeds (only for fid8)\n",
    "    idx_cols = [\"benchmark_id\", \"optimizer_id\", \"task_id\"]\n",
    "    df_final_ppo_fid8 = df_final_ppo[df_final_ppo[\"optimizer_id\"].str.contains(\"Ros\")]\n",
    "    ids = df_final_ppo_fid8.groupby(idx_cols)[\"log_regret\"].mean().groupby([\"benchmark_id\", \"task_id\"]).idxmin()\n",
    "    ids = ids.dropna()\n",
    "    df_final_ppo_vbs = df_final_ppo_fid8.set_index(idx_cols).loc[ids].reset_index()\n",
    "    df_final_ppo_vbs[\"optimizer_id\"] = \"PPO-Ros--vbs\"\n",
    "    # df_final_ppo_vbs = df_final_ppo.groupby([\"benchmark_id\", \"optimizer_id\", \"task_id\", \"seed\"])[\"log_regret\"].min().reset_index().copy()\n",
    "    # df_final_ppo_vbs[\"optimizer_id\"] = df_final_ppo[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1])) + \"--vbs\"\n",
    "\n",
    "    df_final = pd.concat([df_final, df_final_ppo_mean, df_final_ppo_vbs]).reset_index(drop=True)\n",
    "    return df_final\n",
    "\n",
    "def load_logs_to_plot() -> pd.DataFrame:\n",
    "    logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "    logs = logs[[\"benchmark_id\", \"task_id\", \"seed\", \"optimizer_id\", \"n_trials\", \"n_trials_norm\", \"log_regret\"]]\n",
    "    logs = filter_experiments(logs)\n",
    "    logs = fix_log_regret_inf(logs)\n",
    "\n",
    "    ppo_ids = logs[\"optimizer_id\"].str.startswith(\"PPO\")\n",
    "\n",
    "    # Reduce PPO name\n",
    "    logs_ppo = logs[ppo_ids].copy()\n",
    "    logs_ppo[\"outer_seed\"] = logs_ppo[\"optimizer_id\"].map(lambda x: int(x.split(\"--\")[-1].replace(\"seed\", \"\")))\n",
    "    # logs_ppo[\"optimizer_id\"] = logs_ppo[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1]))\n",
    "\n",
    "    # Average over outer seeds (averaging happens during plotting)\n",
    "    # logs_ppo_mean = logs_ppo.groupby([\"benchmark_id\", \"optimizer_id\", \"task_id\", \"seed\", \"n_trials\"])[\"log_regret\"].mean().reset_index().copy()\n",
    "    logs_ppo_mean = logs_ppo.copy()\n",
    "    logs_ppo_mean[\"optimizer_id\"] = logs_ppo_mean[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1]) + \"--mean\")\n",
    "\n",
    "    # vbs = []\n",
    "    # keys = [\"benchmark_id\", \"task_id\", \"seed\"]\n",
    "    # for gid, gdf in logs_ppo.groupby(keys):\n",
    "    #     row = gdf[gdf[\"log_regret\"] == gdf[\"log_regret\"].min()]\n",
    "    #     opt_id = row[\"optimizer_id\"].iloc[0]\n",
    "    #     run = gdf[gdf[\"optimizer_id\"] == opt_id]\n",
    "    #     run[\"optimizer_id\"] = \"--\".join(opt_id.split(\"--\")[:-1]) + \"--vbs\"\n",
    "    #     vbs.append(run)\n",
    "    # vbs = pd.concat(vbs).reset_index(drop=True)\n",
    "\n",
    "    # keys = [\"benchmark_id\", \"task_id\", \"seed\"]\n",
    "\n",
    "    # # find optimizer_id achieving min log_regret per group\n",
    "    # idx = logs_ppo.groupby(keys)[\"log_regret\"].idxmin()\n",
    "    # # idx = (\n",
    "    # #     logs_ppo\n",
    "    # #     .sort_values([\"log_regret\", \"optimizer_id\"])\n",
    "    # #     .groupby(keys)[\"log_regret\"]\n",
    "    # #     .idxmin()\n",
    "    # # )\n",
    "    # vbs_runs = logs_ppo.loc[idx, keys + [\"optimizer_id\"]]\n",
    "\n",
    "    # # keep full anytime trajectory for those optimizers\n",
    "    # vbs = logs_ppo.merge(vbs_runs, on=keys + [\"optimizer_id\"], how=\"inner\")\n",
    "\n",
    "    # # rename optimizer_id to VBS\n",
    "    # vbs[\"optimizer_id\"] = (\n",
    "    #     vbs[\"optimizer_id\"]\n",
    "    #     .str.rsplit(\"--\", n=1)\n",
    "    #     .str[0]\n",
    "    #     .add(\"--vbs\")\n",
    "    # )\n",
    "\n",
    "    # vbs = vbs.reset_index(drop=True)\n",
    "    return pd.concat([logs[~ppo_ids], logs_ppo, logs_ppo_mean]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "df_final = load_df_final()\n",
    "logs = load_logs_to_plot()\n",
    "\n",
    "\n",
    "metabo_ids = [\n",
    "    \"MetaBO-Ros\",\n",
    "    \"MetaBO-BBOB\"\n",
    "]\n",
    "opt_ids = [\n",
    "    \"Static\",\n",
    "    \"SAWEI\",\n",
    "    \"Random\",\n",
    "    \"PPO-Ros--mean\",\n",
    "    \"PPO-Ros--seed1\",\n",
    "    \"PPO-Ros--seed2\",\n",
    "    \"PPO-Ros--seed3\",\n",
    "    \"PPO-Ros--seed4\",\n",
    "    \"PPO-Ros--seed5\",\n",
    "    \"PPO-Ros--vbs\",\n",
    "] + metabo_ids\n",
    "\n",
    "\n",
    "# Palettes\n",
    "palette = get_color_palette(df_final)\n",
    "color_ids = [0,2,1,6,9,10,11,12,13,5,3,4]\n",
    "cmap1 = colorblind_palette\n",
    "cmap2 = sns.color_palette(\"colorblind\", as_cmap=False)\n",
    "cmap3 = sns.color_palette(\"Paired\", as_cmap=False)\n",
    "colormaps = list(cmap1) + list(cmap2) + list(cmap3)\n",
    "colors = [colormaps[idx] for idx in color_ids]\n",
    "palette = dict(zip(opt_ids, colors, strict=True))\n",
    "marker_palette = get_marker_palette(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a5d592",
   "metadata": {},
   "outputs": [],
   "source": [
    "palette"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e736d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 2))\n",
    "for i, color in enumerate(colormaps):\n",
    "    ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=color))\n",
    "    ax.text(i + 0.5, -0.3, str(i), ha='center', va='top', fontsize=8)\n",
    "ax.set_xlim(0, len(colormaps))\n",
    "ax.set_ylim(-0.5, 1)\n",
    "ax.axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "palette_items = list(palette.items())\n",
    "n = len(palette_items)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(max(6, n*0.5), 2))\n",
    "\n",
    "for i, (name, color) in enumerate(palette_items):\n",
    "    ax.add_patch(plt.Rectangle((i, 0), 1, 1, color=color))\n",
    "    ax.text(i + 0.5, -0.3, name, ha='center', va='top', rotation=90, fontsize=8)\n",
    "ax.set_xlim(0, n)\n",
    "ax.set_ylim(-0.5, 1)\n",
    "ax.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4744073d",
   "metadata": {},
   "source": [
    "# Log Regret over Time per Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806ff7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seaborn()\n",
    "\n",
    "logs_to_plot = logs[~logs[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "\n",
    "logs_to_plot = logs_to_plot[\n",
    "    logs_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "\n",
    "logs_to_plot = get_interpolated_performance_df(\n",
    "    logs=logs_to_plot,\n",
    "    interpolation_columns=[\"log_regret\"],\n",
    "    group_keys=[\"benchmark_id\", \"optimizer_id\", \"task_id\", \"seed\"]\n",
    ")\n",
    "n_benchmarks = logs_to_plot[\"benchmark_id\"].nunique()\n",
    "fig = plt.figure(figsize=(4*n_benchmarks, 4))\n",
    "axes = fig.subplots(nrows=1, ncols=n_benchmarks, sharex=False, sharey=False)\n",
    "\n",
    "\n",
    "for i, (benchmark_id, group) in enumerate(logs_to_plot.groupby(\"benchmark_id\")):\n",
    "    # if not benchmark_id.startswith(\"Opt\"):\n",
    "    #     continue\n",
    "    ax = axes[i]\n",
    "    ax = sns.lineplot(data=group, x=\"n_trials_norm\", y=key_performance, hue=\"optimizer_id\", palette=palette, ax=ax,\n",
    "        style=\"optimizer_id\", dashes=False, markers=marker_palette, markevery=4,\n",
    "    )\n",
    "    ax.set_title(benchmark_id)\n",
    "    ax.legend().remove()\n",
    "    ax.set_xlim(0, 1)\n",
    "ax.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57dc3f99",
   "metadata": {},
   "source": [
    "# Log Regret over Time Single per Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a34e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "setup_seaborn()\n",
    "\n",
    "logs_to_plot = logs[~logs[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "logs_to_plot = logs_to_plot[logs_to_plot[\"optimizer_id\"].isin(opt_ids)]\n",
    "for benchmark_id, group in logs_to_plot.groupby(\"benchmark_id\"):\n",
    "    if not benchmark_id.startswith(\"BBOB-2d\"):\n",
    "        continue\n",
    "\n",
    "    grid = sns.FacetGrid(data=group, col=\"task_id\", col_wrap=5, height=3, sharex=True, sharey=False)\n",
    "\n",
    "    for i, (task_id, gdf) in enumerate(group.groupby(\"task_id\")):\n",
    "        ax = grid.axes.flat[i]\n",
    "        ax = sns.lineplot(data=gdf, x=\"n_trials\", y=key_performance, hue=\"optimizer_id\", palette=palette,\n",
    "            style=\"optimizer_id\", dashes=False, markers=marker_palette, markevery=10,\n",
    "            ax=ax\n",
    "        )\n",
    "        ax.set_title(task_id)\n",
    "        ax.legend().remove()\n",
    "        ax.axvline(77)\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1))\n",
    "    # grid.add_legend()\n",
    "    grid.figure.suptitle(benchmark_id)\n",
    "    # grid.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2845564a",
   "metadata": {},
   "source": [
    "# Rosenbrock 2d and 8d Barplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc706ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "skip_plot = df_final[\"optimizer_id\"].nunique() > 20\n",
    "\n",
    "df_final_to_plot = df_final[~df_final[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.contains(\"seed\")]\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.contains(\"vbs\")]\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.contains(\"MetaBO-BBOB\")]\n",
    "df_final_to_plot = df_final_to_plot[\n",
    "    df_final_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "# df_final_to_plot = df_final\n",
    "\n",
    "\n",
    "tasks = [\"bbob/2/8/0\", \"bbob/8/8/0\"]\n",
    "df_final_to_plot = df_final_to_plot[df_final_to_plot[\"task_id\"].isin(tasks)]\n",
    "titles = {\n",
    "    \"bbob/2/8/0\": \"Rosenbrock (2d)\",\n",
    "    \"bbob/8/8/0\": \"Rosenbrock (8d)\",\n",
    "}\n",
    "for k, v in titles.items():\n",
    "    df_final_to_plot.loc[df_final_to_plot[\"task_id\"] == k, \"task_id\"] = v\n",
    "\n",
    "fig = plt.figure(figsize=(7,2.5))\n",
    "axes = fig.subplots(nrows=1, ncols=2, sharey=False, sharex=False)\n",
    "for i, (task_id, gdf) in enumerate(df_final_to_plot.groupby(\"task_id\")):\n",
    "    gdf = sort_df_by_mean(gdf, key_performance=\"log_regret\")\n",
    "\n",
    "    ax = axes[i]\n",
    "    # build optimizer -> hatch map\n",
    "    hatch_map = {\n",
    "        opt: hatch_for_optimizer(opt)\n",
    "        for opt in gdf[\"optimizer_id\"].unique()\n",
    "    }\n",
    "\n",
    "    sns.barplot(\n",
    "        data=gdf,\n",
    "        x=\"log_regret\",\n",
    "        y=\"optimizer_id\",\n",
    "        hue=\"optimizer_id\",\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        dodge=False\n",
    "    )\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ax.set_ylabel(None)\n",
    "    for patch, opt in zip(ax.patches, gdf[\"optimizer_id\"].unique()):\n",
    "        patch.set_hatch(hatch_map.get(opt, \"\"))\n",
    "\n",
    "    ax.set_title(task_id)\n",
    "\n",
    "\n",
    "    df_mean = gdf.groupby(\"optimizer_id\")[key_performance].apply(np.nanmean).sort_values(ascending=False)\n",
    "    print(df_mean)\n",
    "    print(df_mean.loc[\"PPO-Ros--mean\"] - df_mean.loc[\"SAWEI\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/final_Rosenbrock\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e891a82b",
   "metadata": {},
   "source": [
    "# BBOB 2d and 8d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3836cb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "skip_plot = df_final[\"optimizer_id\"].nunique() > 20\n",
    "\n",
    "df_final_to_plot = df_final[~df_final[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "# df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.contains(\"seed\")]\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.contains(\"vbs\")]\n",
    "df_final_to_plot = df_final_to_plot[\n",
    "    df_final_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "# df_final_to_plot = df_final\n",
    "\n",
    "\n",
    "df_final_to_plot = df_final_to_plot[df_final_to_plot[\"benchmark_id\"].str.startswith(\"BBOB\")]\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"optimizer_id\"].str.startswith(\"MetaBO-BBOB\")]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 3))\n",
    "axes = fig.subplots(nrows=1, ncols=df_final_to_plot[\"benchmark_id\"].nunique(), sharey=False, sharex=False)\n",
    "for i, (benchmark_id, gdf) in enumerate(df_final_to_plot.groupby(\"benchmark_id\")):\n",
    "    gdf = sort_df_by_mean(gdf, key_performance=\"log_regret\")\n",
    "    n_trials = 134 if benchmark_id == \"BBOB-8d\" else 77\n",
    "    if n_trials == 77:\n",
    "        gdf[gdf[\"n_trials\"]!=n_trials][[\"optimizer_id\", \"seed\", \"task_id\", \"n_trials\"]].to_csv(\"tmp.csv\")\n",
    "\n",
    "    ax = axes[i]\n",
    "    # build optimizer -> hatch map\n",
    "    hatch_map = {\n",
    "        opt: hatch_for_optimizer(opt)\n",
    "        for opt in gdf[\"optimizer_id\"].unique()\n",
    "    }\n",
    "\n",
    "    sns.barplot(\n",
    "        data=gdf,\n",
    "        x=\"log_regret\",\n",
    "        y=\"optimizer_id\",\n",
    "        hue=\"optimizer_id\",\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        dodge=False,\n",
    "        n_boot=1000,\n",
    "    )\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ax.set_ylabel(None)\n",
    "    for patch, opt in zip(ax.patches, gdf[\"optimizer_id\"].unique()):\n",
    "        patch.set_hatch(hatch_map.get(opt, \"\"))\n",
    "\n",
    "    ax.set_title(benchmark_id)\n",
    "\n",
    "\n",
    "    df_mean = gdf.groupby(\"optimizer_id\")[key_performance].apply(np.nanmean).sort_values(ascending=False)\n",
    "    print(df_mean)\n",
    "    print(df_mean.loc[\"PPO-Ros--mean\"] - df_mean.loc[\"SAWEI\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/final_BBOB\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc19ccd",
   "metadata": {},
   "source": [
    "# OptBench, nasengb, YAHPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hatch_for_optimizer(opt):\n",
    "    if opt.endswith(\"vbs\"):\n",
    "        return \"xx\"\n",
    "    if opt.endswith(\"mean\"):\n",
    "        return \"\\\\\\\\\\\\\"\n",
    "    if opt.endswith(\"--seed\") or \"--seed\" in opt:\n",
    "        return \"\"\n",
    "    if opt in {\"DefaultPolicy\", \"SAWEI-P\", \"Random\"}:\n",
    "        return \"..\"\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "setup_seaborn(font_scale=1.1)\n",
    "\n",
    "skip_plot = df_final[\"optimizer_id\"].nunique() > 20\n",
    "\n",
    "df_final_to_plot = df_final[~df_final[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "df_final_to_plot = df_final_to_plot[\n",
    "    df_final_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "df_final_to_plot = df_final_to_plot[~df_final_to_plot[\"benchmark_id\"].str.startswith(\"BBOB\")]\n",
    "\n",
    "benchmarks = [\"OptBench\", \"nasengb\", \"YAHPO\"]\n",
    "\n",
    "fig = plt.figure(figsize=(8, 3))\n",
    "axes = fig.subplots(nrows=1, ncols=df_final_to_plot[\"benchmark_id\"].nunique(), sharey=False, sharex=False)\n",
    "for i, benchmark_id in enumerate(benchmarks):\n",
    "    gdf = df_final_to_plot[df_final_to_plot[\"benchmark_id\"] == benchmark_id]\n",
    "    # if benchmark_id != \"YAHPO\":\n",
    "    #     gdf = gdf[~gdf[\"optimizer_id\"].str.contains(\"vbs\")]\n",
    "\n",
    "    gdf = sort_df_by_mean(gdf, key_performance=\"log_regret\")\n",
    "\n",
    "    ax = axes[i]\n",
    "    # build optimizer -> hatch map\n",
    "    hatch_map = {\n",
    "        opt: hatch_for_optimizer(opt)\n",
    "        for opt in gdf[\"optimizer_id\"].unique()\n",
    "    }\n",
    "\n",
    "    sns.barplot(\n",
    "        data=gdf,\n",
    "        x=\"log_regret\",\n",
    "        y=\"optimizer_id\",\n",
    "        hue=\"optimizer_id\",\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        dodge=False\n",
    "    )\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ax.set_ylabel(None)\n",
    "    for patch, opt in zip(ax.patches, gdf[\"optimizer_id\"].unique()):\n",
    "        patch.set_hatch(hatch_map.get(opt, \"\"))\n",
    "\n",
    "    ax.set_title(benchmark_id)\n",
    "\n",
    "\n",
    "    df_mean = gdf.groupby(\"optimizer_id\")[key_performance].apply(np.nanmean).sort_values(ascending=False)\n",
    "    print(df_mean)\n",
    "    print(df_mean.loc[\"PPO-Ros--mean\"] - df_mean.loc[\"SAWEI\"])\n",
    "\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/final_otherbenchmarks\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8a503c",
   "metadata": {},
   "source": [
    "# YAHPO single task box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf6728",
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_seaborn(font_scale=1.1)\n",
    "\n",
    "skip_plot = df_final[\"optimizer_id\"].nunique() > 20\n",
    "\n",
    "df_final_to_plot = df_final[~df_final[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "df_final_to_plot = df_final_to_plot[\n",
    "    df_final_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "df_final_to_plot = df_final_to_plot[df_final_to_plot[\"benchmark_id\"] == \"YAHPO\"]\n",
    "\n",
    "\n",
    "df_final_to_plot = sort_df_by_mean(df_final_to_plot, key_performance=\"log_regret\")\n",
    "\n",
    "grid = sns.FacetGrid(data=df_final_to_plot, col=\"task_id\", hue=\"optimizer_id\", palette=palette,\n",
    "                     col_wrap=5, sharey=False, sharex=False)\n",
    "grid.map_dataframe(sns.barplot, x=\"log_regret\", y=\"optimizer_id\")\n",
    "\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/final_yahpo_single\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7ddd46",
   "metadata": {},
   "source": [
    "# MetaBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634dcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metabo = pd.read_csv(metabo_fn)\n",
    "df_metabo[\"n_trials_norm\"] = df_metabo.groupby(\"task_id\")[\"n_trials\"].transform(normalize)\n",
    "df_metabo = filter_only_final_performance(df_metabo, key_performance=\"log_regret\")\n",
    "print(df_metabo[\"n_trials\"].unique())\n",
    "df_metabo[\"fid\"] = df_metabo[\"task_id\"].map(lambda x: int(x.split(\"/\")[2]))\n",
    "df_metabo[\"dim\"] = df_metabo[\"task_id\"].map(lambda x: int(x.split(\"/\")[1]))\n",
    "df_metabo[\"task_id\"] = df_metabo[\"fid\"].map(str) + \"-\" + df_metabo[\"dim\"].map(str) + \"d\"\n",
    "df_metabo[\"optimizer_id\"] = df_metabo[\"optimizer_id\"].map(lambda x: \"MetaBO-all\" if \"BBOB-2D\" in x else f\"MetaBO-{int(x.split('-')[2]):02d}\")\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "axes = fig.subplots(nrows=1, ncols=2, sharex=False, sharey=False)\n",
    "\n",
    "\n",
    "palette = get_color_palette(df_metabo)\n",
    "\n",
    "df_metabo_2d = sort_df_by_mean(df_metabo_2d, key_performance=\"log_regret\")\n",
    "df_mean = df_metabo_2d.groupby(\"optimizer_id\")[\"log_regret\"].apply(np.nanmean).sort_values(ascending=False)\n",
    "print(df_mean)\n",
    "ax = axes[0]\n",
    "ax = sns.barplot(\n",
    "    data=df_metabo_2d, x=\"log_regret\", y=\"optimizer_id\", hue=\"optimizer_id\", palette=palette, ax=ax)\n",
    "ax.set_title(\"BBOB (2d)\")\n",
    "ax.set_xlabel(\"Log Regret\")\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "\n",
    "df_metabo_8d = df_metabo[df_metabo[\"dim\"] == 8]\n",
    "df_metabo_8d = sort_df_by_mean(df_metabo_8d, key_performance=\"log_regret\")\n",
    "df_mean = df_metabo_8d.groupby(\"optimizer_id\")[\"log_regret\"].apply(np.nanmean).sort_values(ascending=False)\n",
    "print(df_mean)\n",
    "ax = axes[1]\n",
    "ax = sns.barplot(\n",
    "    data=df_metabo_8d, x=\"log_regret\", y=\"optimizer_id\", hue=\"optimizer_id\", palette=palette, ax=ax)\n",
    "ax.set_title(\"BBOB (8d)\")\n",
    "ax.set_xlabel(\"Log Regret\")\n",
    "ax.set_ylabel(None)\n",
    "\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/final_metabo\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9886bbe",
   "metadata": {},
   "source": [
    "# Good seed is good?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65e77f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgos_to_plot = logs[\n",
    "    (logs[\"optimizer_id\"] == \"PPO-Ros--seed5\") & (logs[\"task_id\"] == \"bbob/2/8/0\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5f722",
   "metadata": {},
   "source": [
    "# Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1243d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(df, palette, title):\n",
    "    fig = plt.figure(figsize=(4, 3))\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "    # build optimizer -> hatch map\n",
    "    optimizer_order = df[\"optimizer_id\"].unique()\n",
    "    hatch_map = {\n",
    "        opt: hatch_for_optimizer(opt)\n",
    "        for opt in df[\"optimizer_id\"].unique()\n",
    "    }\n",
    "\n",
    "    # --- barplot ---\n",
    "    sns.barplot(\n",
    "        data=df,\n",
    "        x=\"log_regret\",\n",
    "        y=\"optimizer_id\",\n",
    "        hue=\"optimizer_id\",\n",
    "        palette=palette,\n",
    "        ax=ax,\n",
    "        dodge=False\n",
    "    )\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ax.set_ylabel(None)\n",
    "\n",
    "    # apply hatches to barplot patches\n",
    "    for patch, opt in zip(ax.patches, df[\"optimizer_id\"].unique()):\n",
    "        patch.set_hatch(hatch_map.get(opt, \"\"))\n",
    "\n",
    "    fig.suptitle(title)\n",
    "    savefig(fig, f\"figures/results_icml/final_{title.replace('/','_').replace('(', '').replace(')', '').replace(' ', '')}\")\n",
    "    plt.show()\n",
    "\n",
    "    # # ######################## Ranks\n",
    "    # rank_df = df.assign(\n",
    "    #     rank=df.groupby([\"task_id\", \"seed\"])[\"log_regret\"]\n",
    "    #         .rank(method=\"average\", ascending=True)\n",
    "    # )\n",
    "    # rank_df = sort_df_by_mean(rank_df, key_performance=\"rank\")\n",
    "\n",
    "    # # --- plot ---\n",
    "    # plt.figure(figsize=(3, 2.5))\n",
    "    # ax = sns.barplot(\n",
    "    #     data=rank_df,\n",
    "    #     x=\"rank\",\n",
    "    #     y=\"optimizer_id\",\n",
    "    #     hue=\"optimizer_id\",\n",
    "    #     palette=palette\n",
    "    # )\n",
    "\n",
    "    # # apply hatches\n",
    "    # for patch, opt in zip(ax.patches, df[\"optimizer_id\"].unique()):\n",
    "    #     patch.set_hatch(hatch_map.get(opt, \"\"))\n",
    "    #     patch.set_edgecolor(\"white\")\n",
    "    #     patch.set_linewidth(1.5)\n",
    "\n",
    "    # ax.set_xlabel(\"Mean Rank (lower is better)\")\n",
    "    # ax.set_ylabel(\"Optimizer\")\n",
    "    # ax.set_title(\"Optimizer Ranking by Mean Rank\")\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "skip_plot = df_final[\"optimizer_id\"].nunique() > 20\n",
    "\n",
    "df_final_to_plot = df_final[~df_final[\"optimizer_id\"].str.contains(\"bbob\")].copy()\n",
    "opt_ids = [\"Static\", \"SAWEI\", \"Random\", \"PPO-Ros--seed5\", \"PPO-Ros--mean\"]\n",
    "df_final_to_plot = df_final_to_plot[\n",
    "    df_final_to_plot[\"optimizer_id\"].isin(opt_ids)\n",
    "]\n",
    "# df_final_to_plot = df_final\n",
    "\n",
    "\n",
    "tasks = [\"bbob/2/8/0\", \"bbob/8/8/0\"]\n",
    "titles = {\n",
    "    \"bbob/2/8/0\": \"Rosenbrock (2d)\",\n",
    "    \"bbob/8/8/0\": \"Rosenbrock (8d)\",\n",
    "}\n",
    "for task_id in tasks:\n",
    "    df_task = df_final_to_plot[df_final_to_plot[\"task_id\"] == task_id]\n",
    "    df_task = sort_df_by_mean(df_task, key_performance=\"log_regret\")\n",
    "\n",
    "    df_task_mean = df_task.groupby(\"optimizer_id\")[key_performance].apply(np.nanmean).sort_values(ascending=False)\n",
    "    df_task_mean.to_csv(f\"finalmean_{task_id.replace('/','_')}.csv\")\n",
    "\n",
    "    if not skip_plot:\n",
    "        plot(df_task, palette, titles[task_id])\n",
    "\n",
    "for benchmark_id, gdf in df_final_to_plot.groupby(\"benchmark_id\"):\n",
    "    n_tasks = gdf[\"task_id\"].nunique()\n",
    "\n",
    "    valid_opts = (\n",
    "        gdf.groupby(\"optimizer_id\")[\"task_id\"]\n",
    "        .nunique()\n",
    "        .loc[lambda s: s == n_tasks]\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    gdf = gdf[gdf[\"optimizer_id\"].isin(valid_opts)]\n",
    "\n",
    "    gdf = sort_df_by_mean(gdf, key_performance=\"log_regret\")\n",
    "\n",
    "    gdf_mean = gdf.groupby(\"optimizer_id\")[key_performance].apply(np.nanmean).sort_values(ascending=False)\n",
    "    gdf_mean.to_csv(f\"finalmean_{benchmark_id.replace('/','_')}.csv\")\n",
    "\n",
    "    if not skip_plot:\n",
    "        plot(gdf, palette, benchmark_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03762afb",
   "metadata": {},
   "source": [
    "# 2d fid8: Final Log Regret Boxplot & Log Regret over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b709944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import (\n",
    "    filter_only_final_performance,\n",
    "    get_color_palette,\n",
    "    get_marker_palette,\n",
    "    savefig,\n",
    "    setup_seaborn,\n",
    ")\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs.loc[logs[\"optimizer_id\"] == \"NoOpPolicy\", \"optimizer_id\"] = \"DefaultPolicy\"\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "# print(logs[\"optimizer_id\"].unique())\n",
    "\n",
    "# logs = logs[\n",
    "#     # (logs[\"task_id\"] == \"bbob/2/8/0\") \\\n",
    "#     (~logs[\"optimizer_id\"].str.contains(\"bbob2d_3\")) \\\n",
    "#     # & (~logs[\"optimizer_id\"].str.contains(\"eplen\")) \\\n",
    "#     & (~logs[\"optimizer_id\"].str.contains(\"episode\")) \\\n",
    "#     # & (~logs[\"optimizer_id\"].str.contains(\"symlog\")) \\\n",
    "#     & (~logs[\"optimizer_id\"].str.contains(\"SMAC-\")) \\\n",
    "#     & (~logs[\"optimizer_id\"].str.contains(\"SMAC3-\")) \\\n",
    "#     # & (~logs[\"optimizer_id\"].str.contains(\"PPO-\")) \\\n",
    "# ]\n",
    "logs = logs[\n",
    "    (logs[\"optimizer_id\"].isin([\"DefaultPolicy\", \"NoOpPolicy\", \"Random\", \"SAWEI-P\"])) \\\n",
    "    | ((logs[\"optimizer_id\"].str.contains(\"symlog\")) \\\n",
    "    & (logs[\"optimizer_id\"].str.contains(\"cont\")) \\\n",
    "    & (logs[\"optimizer_id\"].str.contains(\"fid8\")) \\\n",
    "    & (logs[\"optimizer_id\"].str.contains(\"DefaultAction\")) \\\n",
    "    & (logs[\"optimizer_id\"].str.contains(\"norm\")) \\\n",
    "    )\n",
    "]\n",
    "# logs_ppo = logs[logs[\"optimizer_id\"].str.startswith(\"PPO\")].copy()\n",
    "# logs_ppo[\"train_seed\"] = logs_ppo[\"optimizer_id\"].map(lambda x: int(x.split(\"--\")[-1].replace(\"seed\", \"\")))\n",
    "# logs_ppo[\"optimizer_id\"] = logs[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1]))\n",
    "# logs = pd.concat([logs, logs_ppo]).reset_index(drop=True)\n",
    "# palette = get_color_palette(logs)\n",
    "# markers = get_marker_palette(logs)\n",
    "\n",
    "def reduce_ppo(logs: pd.DataFrame) -> pd.DataFrame:\n",
    "    logs_ppo = logs[logs[\"optimizer_id\"].str.startswith(\"PPO\")].copy()\n",
    "    logs_ppo[\"train_seed\"] = logs_ppo[\"optimizer_id\"].map(lambda x: int(x.split(\"--\")[-1].replace(\"seed\", \"\")))\n",
    "    logs_ppo[\"optimizer_id\"] = logs[\"optimizer_id\"].map(lambda x: \"--\".join(x.split(\"--\")[:-1]))\n",
    "    logs = pd.concat([logs, logs_ppo]).reset_index(drop=True)\n",
    "    return logs\n",
    "\n",
    "for task_id in [\"bbob/2/8/0\", \"bbob/8/8/0\"]:\n",
    "    logs_to_plot = logs[logs[\"task_id\"] == task_id]\n",
    "    logs_to_plot = sort_df_by_mean(logs_to_plot, key_performance=key_performance)\n",
    "    df_final = filter_only_final_performance(logs_to_plot)\n",
    "\n",
    "    logs_to_plot = reduce_ppo(logs_to_plot)\n",
    "    df_final = reduce_ppo(df_final)\n",
    "\n",
    "    palette = get_color_palette(logs_to_plot)\n",
    "    markers = get_marker_palette(logs_to_plot)\n",
    "\n",
    "\n",
    "    df_final = sort_df_by_mean(df_final, key_performance=key_performance)\n",
    "    hue_order = logs_to_plot[\"optimizer_id\"].unique()\n",
    "\n",
    "    fig = plt.figure(figsize=(15,4))\n",
    "    axes = fig.subplots(ncols=3, sharex=False, sharey=False)\n",
    "    ax = axes[2]\n",
    "    ax = sns.lineplot(data=logs_to_plot, x=\"n_trials\", y=key_performance, hue=\"optimizer_id\", palette=palette,\n",
    "                style=\"optimizer_id\", dashes=False, markers=markers, markevery=14, linewidth=2,\n",
    "                # estimator=None, units=\"seed\", linewidth=0.5,\n",
    "                ax=ax, hue_order=hue_order,\n",
    "                )\n",
    "    ax.legend(title=\"Policy\", bbox_to_anchor=(1.05, 1))\n",
    "    ax.set_xlim(logs_to_plot[\"n_trials\"].min(), logs_to_plot[\"n_trials\"].max())\n",
    "    ax.set_xlabel(\"$n_\\\\mathrm{trials}$\")\n",
    "    ax.set_ylabel(\"Log Regret\")\n",
    "\n",
    "    ax = axes[0]\n",
    "    ax = sns.boxplot(data=df_final, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", palette=palette, ax=ax)\n",
    "    ax.set_ylabel(\"Policy\")\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "\n",
    "    sns.stripplot(\n",
    "        data=df_final,\n",
    "        y=\"optimizer_id\",\n",
    "        color=\"k\",\n",
    "        # hue=\"optimizer_id\",\n",
    "        # palette=palette,\n",
    "        x=\"log_regret\",\n",
    "        order=hue_order,\n",
    "        jitter=0.25,\n",
    "        size=3,\n",
    "        alpha=0.6,\n",
    "        ax=ax\n",
    "    )\n",
    "\n",
    "    ax = axes[1]\n",
    "    ax = sns.barplot(data=df_final, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", palette=palette, ax=ax)\n",
    "    ax.set_ylabel(None)\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    fn = \"figures/results_icml/fid8_8d\" if not \"2\" in task_id else \"figures/results_icml/fid8_2d\"\n",
    "    savefig(fig=fig, filename=fn)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142bd775",
   "metadata": {},
   "source": [
    "# Fid8: 2d and 8d boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf462c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import (\n",
    "    filter_only_final_performance,\n",
    "    get_color_palette,\n",
    "    get_marker_palette,\n",
    "    savefig,\n",
    "    setup_seaborn,\n",
    ")\n",
    "from carps.analysis.gather_data import normalize\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "key_performance = \"log_regret\"\n",
    "palette = get_color_palette(logs)\n",
    "logs = logs[\n",
    "    (logs[\"task_id\"].isin([\"bbob/2/8/0\",\"bbob/8/8/0\"])) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"bbob2d_3\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"-SMAC\")) \\\n",
    "]\n",
    "logs.loc[logs[\"task_id\"] == \"bbob/2/8/0\", \"task_id\"] = \"Rosenbrock-2d\"\n",
    "logs.loc[logs[\"task_id\"] == \"bbob/8/8/0\", \"task_id\"] = \"Rosenbrock-8d\"\n",
    "palette = get_color_palette(logs)\n",
    "logs = sort_df_by_mean(logs, key_performance=key_performance)\n",
    "logs = logs.sort_values(\n",
    "    by=\"task_id\",\n",
    "    key=lambda x: x.str.extract('(\\d+)')[0].astype(int)\n",
    ")\n",
    "df_final = filter_only_final_performance(logs)\n",
    "\n",
    "key_performance = \"Log Regret (Normalized)\"\n",
    "df_final[key_performance] = df_final.groupby(\"task_id\")[\"log_regret\"].transform(normalize)\n",
    "df_final = df_final.sort_values(\n",
    "    by=\"task_id\",\n",
    "    key=lambda x: x.str.extract('(\\d+)')[0].astype(int)\n",
    ")\n",
    "df_final = sort_df_by_mean(df_final, key_performance=key_performance)\n",
    "hue_order = logs[\"optimizer_id\"].unique()\n",
    "markers = get_marker_palette(logs)\n",
    "\n",
    "fig = plt.figure(figsize=(10,3.5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(\n",
    "    data=df_final, y=key_performance, hue=\"optimizer_id\", x=\"task_id\", palette=palette, ax=ax)\n",
    "ax.legend(title=\"Policy\", bbox_to_anchor=(1.05,1))\n",
    "# ax.tick_params(axis=\"x\", rotation=90)\n",
    "ax.set_xlabel(\"Task ID\")\n",
    "fig.tight_layout()\n",
    "savefig(fig=fig, filename=\"figures/results_icml/fid8_2d_vs_8d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8678a28",
   "metadata": {},
   "source": [
    "# Fid8 Generalization on BBOB 2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7952dc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import (\n",
    "    filter_only_final_performance,\n",
    "    get_color_palette,\n",
    "    get_marker_palette,\n",
    "    savefig,\n",
    "    setup_seaborn,\n",
    ")\n",
    "from carps.analysis.gather_data import normalize\n",
    "from matplotlib.lines import Line2D\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "key_performance = \"log_regret\"\n",
    "palette = get_color_palette(logs)\n",
    "logs = logs[\n",
    "    (logs[\"task_id\"].str.startswith(\"bbob/2\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"bbob2d_3\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"episode\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"-SMAC\")) \\\n",
    "]\n",
    "print(logs[\"task_id\"].unique())\n",
    "palette = get_color_palette(logs)\n",
    "logs = sort_df_by_mean(logs, key_performance=key_performance)\n",
    "df_final = filter_only_final_performance(logs)\n",
    "\n",
    "# -----------------------------\n",
    "# Sort optimizers by performance\n",
    "# -----------------------------\n",
    "optimizer_order = (\n",
    "    df_final\n",
    "    .groupby(\"optimizer_id\")[\"regret\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    "    .index\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Automatic floor for -inf\n",
    "# -----------------------------\n",
    "finite_vals = df_final.loc[\n",
    "    np.isfinite(df_final[\"log_regret\"]),\n",
    "    \"log_regret\"\n",
    "]\n",
    "floor = finite_vals.min() - 0.5\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare plotting DataFrame\n",
    "# -----------------------------\n",
    "df_plot = df_final.copy()\n",
    "df_plot[\"solved\"] = df_plot[\"log_regret\"].eq(-np.inf)\n",
    "df_plot[\"log_regret_plot\"] = df_plot[\"log_regret\"].replace(-np.inf, floor)\n",
    "\n",
    "df_plot[\"optimizer_id\"] = pd.Categorical(\n",
    "    df_plot[\"optimizer_id\"],\n",
    "    categories=optimizer_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Main plot: boxplot + jitter + annotations\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df_plot,\n",
    "    y=\"optimizer_id\",\n",
    "    hue=\"optimizer_id\",\n",
    "    palette=palette,\n",
    "    x=\"log_regret_plot\",\n",
    "    order=optimizer_order,\n",
    "    jitter=0.25,\n",
    "    size=3,\n",
    "    alpha=0.6,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_plot,\n",
    "    y=\"optimizer_id\",\n",
    "    x=\"log_regret_plot\",\n",
    "    hue=\"optimizer_id\",\n",
    "    palette=palette,\n",
    "    order=optimizer_order,\n",
    "    width=0.6,\n",
    "    fliersize=0,\n",
    "    ax=ax,\n",
    "    fill=False,\n",
    "    zorder=9999,\n",
    "    linewidth=3,\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1.5},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Annotate solved counts\n",
    "solved_counts = df_plot.groupby(\"optimizer_id\")[\"solved\"].sum()\n",
    "\n",
    "for y, opt in enumerate(optimizer_order):\n",
    "    ax.text(\n",
    "        floor + 0.02,\n",
    "        y,\n",
    "        f\"{solved_counts[opt]} solved\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "ax.axvline(floor, linestyle=\"--\", linewidth=2, color=\"gray\")\n",
    "ax.set_xlabel(\"Final Log Regret\")\n",
    "ax.set_ylabel(\"Policy\")\n",
    "plt.tight_layout()\n",
    "savefig(fig=fig, filename=\"figures/results_icml/fid8_2d_vs_bbob2d\")\n",
    "plt.show()\n",
    "\n",
    "# key_performance_norm = \"Log Regret (Normalized)\"\n",
    "# df_final[key_performance_norm] = df_final.groupby(\"task_id\")[\"log_regret\"].transform(normalize)\n",
    "\n",
    "# df_final = sort_df_by_mean(df_final, key_performance=key_performance_norm)\n",
    "# hue_order = logs[\"optimizer_id\"].unique()\n",
    "# markers = get_marker_palette(logs)\n",
    "\n",
    "# fig = plt.figure(figsize=(10,3.5))\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax = sns.boxplot(\n",
    "#     data=df_final, x=key_performance_norm, hue=\"optimizer_id\", y=\"optimizer_id\", palette=palette, ax=ax)\n",
    "# # ax.tick_params(axis=\"x\", rotation=90)\n",
    "# ax.set_xlabel(\"Log Regret (Normalized)\")\n",
    "# ax.set_ylabel(\"Policy\")\n",
    "# fig.tight_layout()\n",
    "# savefig(fig=fig, filename=\"figures/results_icml/fid8_2d_vs_8d\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851f28c",
   "metadata": {},
   "source": [
    "# BBOB2d on BBOB2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dac0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import importlib\n",
    "import adaptaf.utils as au\n",
    "importlib.reload(au)\n",
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import (\n",
    "    filter_only_final_performance,\n",
    "    get_color_palette,\n",
    "    get_marker_palette,\n",
    "    savefig,\n",
    "    setup_seaborn,\n",
    ")\n",
    "from carps.analysis.gather_data import normalize\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "key_performance = \"log_regret\"\n",
    "\n",
    "palette = get_color_palette(logs)\n",
    "logs = logs[\n",
    "    (logs[\"task_id\"].str.startswith(\"bbob/2\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"fid8\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"-SMAC\")) \\\n",
    "    & (~logs[\"optimizer_id\"].str.contains(\"episode\")) \\\n",
    "]\n",
    "palette = get_color_palette(logs)\n",
    "df_final = filter_only_final_performance(logs)\n",
    "\n",
    "# -----------------------------\n",
    "# Sort optimizers by performance\n",
    "# -----------------------------\n",
    "optimizer_order = (\n",
    "    df_final\n",
    "    .groupby(\"optimizer_id\")[\"regret\"]\n",
    "    .mean()\n",
    "    .sort_values()\n",
    "    .index\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Automatic floor for -inf\n",
    "# -----------------------------\n",
    "finite_vals = df_final.loc[\n",
    "    np.isfinite(df_final[\"log_regret\"]),\n",
    "    \"log_regret\"\n",
    "]\n",
    "floor = finite_vals.min() - 0.5\n",
    "\n",
    "# -----------------------------\n",
    "# Prepare plotting DataFrame\n",
    "# -----------------------------\n",
    "df_plot = df_final.copy()\n",
    "df_plot[\"solved\"] = df_plot[\"log_regret\"].eq(-np.inf)\n",
    "df_plot[\"log_regret_plot\"] = df_plot[\"log_regret\"].replace(-np.inf, floor)\n",
    "\n",
    "df_plot[\"optimizer_id\"] = pd.Categorical(\n",
    "    df_plot[\"optimizer_id\"],\n",
    "    categories=optimizer_order,\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# Main plot: boxplot + jitter + annotations\n",
    "# -----------------------------\n",
    "fig, ax = plt.subplots(figsize=(8, 4))\n",
    "\n",
    "\n",
    "sns.stripplot(\n",
    "    data=df_plot,\n",
    "    y=\"optimizer_id\",\n",
    "    hue=\"optimizer_id\",\n",
    "    palette=palette,\n",
    "    x=\"log_regret_plot\",\n",
    "    order=optimizer_order,\n",
    "    jitter=0.25,\n",
    "    size=3,\n",
    "    alpha=0.6,\n",
    "    ax=ax\n",
    ")\n",
    "\n",
    "sns.boxplot(\n",
    "    data=df_plot,\n",
    "    y=\"optimizer_id\",\n",
    "    x=\"log_regret_plot\",\n",
    "    hue=\"optimizer_id\",\n",
    "    palette=palette,\n",
    "    order=optimizer_order,\n",
    "    width=0.6,\n",
    "    fliersize=0,\n",
    "    ax=ax,\n",
    "    fill=False,\n",
    "    zorder=9999,\n",
    "    linewidth=3,\n",
    "    medianprops={\"color\": \"black\", \"linewidth\": 1.5},\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Annotate solved counts\n",
    "solved_counts = df_plot.groupby(\"optimizer_id\")[\"solved\"].sum()\n",
    "\n",
    "for y, opt in enumerate(optimizer_order):\n",
    "    ax.text(\n",
    "        floor + 0.02,\n",
    "        y,\n",
    "        f\"{solved_counts[opt]} solved\",\n",
    "        va=\"center\",\n",
    "        ha=\"left\",\n",
    "        fontsize=8\n",
    "    )\n",
    "\n",
    "ax.axvline(floor, linestyle=\"--\", linewidth=2, color=\"gray\")\n",
    "ax.set_xlabel(\"Final Log Regret\")\n",
    "ax.set_ylabel(\"Policy\")\n",
    "plt.tight_layout()\n",
    "savefig(fig=fig, filename=\"figures/results_icml/bbob2d_on_bbob2d\")\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936eca87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Heatmap with solved counts per cell\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Prepare data: number of runs solved per task & optimizer\n",
    "# 1 if log_regret = -inf, 0 otherwise\n",
    "df_solved = df_final.copy()\n",
    "df_solved[\"solved\"] = (df_solved[\"log_regret\"] == -np.inf).astype(int)\n",
    "\n",
    "# Pivot table: tasks x optimizers, sum over multiple runs\n",
    "task_counts = df_solved.pivot_table(\n",
    "    index=\"task_id\",\n",
    "    columns=\"optimizer_id\",\n",
    "    values=\"solved\",\n",
    "    aggfunc=\"sum\",\n",
    "    fill_value=0\n",
    ").reindex(columns=optimizer_order)\n",
    "\n",
    "# Binary mask for heatmap coloring: 1 = solved at least once\n",
    "task_binary = (task_counts > 0).astype(int)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "\n",
    "# Base heatmap: solved vs not solved\n",
    "sns.heatmap(\n",
    "    task_counts.T,\n",
    "    cbar=False,\n",
    "    linewidths=0.3,\n",
    "    linecolor=\"gray\",\n",
    "    cmap=\"Greens\",\n",
    "    ax=ax,\n",
    "    annot=task_counts.T,      # overlay the **number of solved runs**\n",
    "    fmt=\"d\",\n",
    "    annot_kws={\"fontsize\": 8, \"fontweight\": \"bold\"}\n",
    ")\n",
    "\n",
    "ax.set_ylabel(\"Policy\")\n",
    "ax.set_xlabel(\"Task ID\")\n",
    "ax.set_title(\"Tasks on which the solution was found (numbers = solved runs)\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "savefig(fig=fig, filename=\"figures/results_icml/sol_found_bbob2d\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68924550",
   "metadata": {},
   "source": [
    "# Final Log Regret Agg Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1b55df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import filter_only_final_performance, savefig\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "\n",
    "logs = logs[logs[\"benchmark_id\"] != \"BBOB-2d\"]\n",
    "# logs = logs[\n",
    "#         # (~logs[\"optimizer_id\"].str.contains(\"fid8\")) \\\n",
    "#         # & (~logs[\"optimizer_id\"].str.contains(\"-SAWEI\")) \\\n",
    "#         # & (~logs[\"optimizer_id\"].str.contains(\"-SMAC\")) \\\n",
    "#         # & (~logs[\"optimizer_id\"].str.contains(\"sym\")) \n",
    "# ]\n",
    "logs.loc[logs[\"optimizer_id\"] == \"NoOpPolicy\", \"optimizer_id\"] = \"DefaultPolicy\"\n",
    "opts_to_plot = [\n",
    "    \"PPO-AlphaNet--dacbo_Csymlogregret_AWEI-cont_Ssawei_Rsymlogregret-SMAC3-BlackBoxFacade_Ibbob2d_3seeds--seed3\",\n",
    "    \"SAWEI-P\",\n",
    "    \"DefaultPolicy\",\n",
    "    \"Random\"\n",
    "]\n",
    "logs = logs[logs[\"optimizer_id\"].isin(opts_to_plot)]\n",
    "df_final = filter_only_final_performance(logs)\n",
    "\n",
    "finite_vals = df_final.loc[\n",
    "    np.isfinite(df_final[\"log_regret\"]),\n",
    "    \"log_regret\"\n",
    "]\n",
    "floor = finite_vals.min() - 0.5\n",
    "df_plot[\"solved\"] = df_plot[\"log_regret\"].eq(-np.inf)\n",
    "df_plot[\"log_regret\"] = df_plot[\"log_regret\"].replace(-np.inf, floor)\n",
    "\n",
    "methods_overview_plot = df_final[\"optimizer_id\"].unique()\n",
    "\n",
    "n_benchmarks = df_final[\"benchmark_id\"].nunique()\n",
    "benchmark_ids = df_final[\"benchmark_id\"].unique()\n",
    "color_palette = get_color_palette(df_final)\n",
    "# color_palette[\"SAWEI-P\"] = \"red\"\n",
    "# color_palette[\"DefaultPolicy\"] = \"green\"\n",
    "# color_palette[\"Random\"] = \"blue\"\n",
    "\n",
    "fig = plt.figure(figsize=(4 * n_benchmarks, 3 * n_benchmarks))\n",
    "axes = fig.subplots(ncols=1, nrows=n_benchmarks, sharex=False, sharey=False)\n",
    "# axes = fig.subplots(nrows=1, ncols=n_benchmarks, sharex=False, sharey=False)\n",
    "\n",
    "for i, benchmark_id in enumerate(benchmark_ids):\n",
    "    ax = axes[i]\n",
    "    # df_bench = df_final[\n",
    "    #     (df_final[\"benchmark_id\"] == benchmark_id) & \\\n",
    "    #     (\n",
    "    #         df_final[\"optimizer_id\"].str.contains(\"fid8\") | \\\n",
    "    #      df_final[\"optimizer_id\"].str.contains(\"Default\") | \\\n",
    "    #      df_final[\"optimizer_id\"].str.contains(\"Random\") | \\\n",
    "    #      df_final[\"optimizer_id\"].str.contains(\"SAWEI-P\") \\\n",
    "    #     #  | df_final[\"optimizer_id\"].str.contains(\"SMAC\") \\\n",
    "    #      | df_final[\"optimizer_id\"].str.contains(\"symlog\") \\\n",
    "    #      )\n",
    "    # ]\n",
    "    df_bench = df_final[\n",
    "        (df_final[\"benchmark_id\"] == benchmark_id) \\\n",
    "    ]\n",
    "    df_bench = sort_df_by_mean(df_bench, key_performance=key_performance)\n",
    "    ax = sns.barplot(\n",
    "        data=df_bench, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", palette=color_palette, ax=ax)\n",
    "\n",
    "    yticklabels = ax.get_yticklabels()\n",
    "    ax.set_title(benchmark_id)\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ylabel = \"Optimizer\" if i == 0 else None\n",
    "    ax.set_ylabel(ylabel)\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/perf_per_benchmark\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_reduced = df_final.groupby([\"optimizer_id\", \"benchmark_id\"])[key_performance].mean().reset_index()\n",
    "df_reduced = sort_df_by_mean(data=df_reduced, key_performance=key_performance)\n",
    "df_reduced_reduced = df_reduced.groupby([\"optimizer_id\"])[key_performance].mean().reset_index()\n",
    "df_reduced_reduced = sort_df_by_mean(data=df_reduced_reduced, key_performance=key_performance)\n",
    "fig = plt.figure(figsize=(6,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax = sns.boxplot(data=df_reduced, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", ax=ax, palette=color_palette)\n",
    "ax = sns.stripplot(data=df_reduced, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", ax=ax, palette=color_palette, linewidth=1, jitter=False)\n",
    "ax = sns.stripplot(\n",
    "    data=df_reduced_reduced, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\", ax=ax,\n",
    "    palette=color_palette, linewidth=1, size=10, marker=\"d\", jitter=False)\n",
    "yticklabels = ax.get_yticklabels()\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], marker=\"o\", color=\"w\", label=\"Mean per Benchmark\",\n",
    "           markerfacecolor=\"grey\", markersize=5),  # small circle\n",
    "    Line2D([0], [0], marker=\"d\", color=\"w\", label=\"Mean\",\n",
    "           markerfacecolor=\"grey\", markersize=10)   # larger diamond\n",
    "]\n",
    "ax.legend(handles=legend_elements, bbox_to_anchor=(0.5, -0.25), ncols=2, fontsize=10, loc=\"upper center\")\n",
    "ax.set_xlabel(\"Log Regret\")\n",
    "ax.set_ylabel(\"Optimizer\")\n",
    "savefig(fig, \"figures/results_icml/perf_on_all\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9557a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dacboenv.experiment.analysis.utils import sort_df_by_mean\n",
    "from carps.analysis.utils import filter_only_final_performance, savefig\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn(font_scale=1.2)\n",
    "\n",
    "# df_final = pd.read_parquet(df_final_fn)\n",
    "logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "\n",
    "finite_vals = df_final.loc[\n",
    "    np.isfinite(df_final[\"log_regret\"]),\n",
    "    \"log_regret\"\n",
    "]\n",
    "floor = finite_vals.min() - 0.5\n",
    "df_plot[\"solved\"] = df_plot[\"log_regret\"].eq(-np.inf)\n",
    "df_plot[\"log_regret\"] = df_plot[\"log_regret\"].replace(-np.inf, floor)\n",
    "\n",
    "methods_overview_plot = df_final[\"optimizer_id\"].unique()\n",
    "\n",
    "n_benchmarks = df_final[\"benchmark_id\"].nunique()\n",
    "benchmark_ids = df_final[\"benchmark_id\"].unique()\n",
    "color_palette = get_color_palette(df_final)\n",
    "\n",
    "fig = plt.figure(figsize=(5 * n_benchmarks, 4))\n",
    "axes = fig.subplots(nrows=1, ncols=n_benchmarks, sharex=False, sharey=False)\n",
    "\n",
    "for i, benchmark_id in enumerate(benchmark_ids):\n",
    "    ax = axes[i]\n",
    "    df_bench = df_final[\n",
    "        (df_final[\"benchmark_id\"] == benchmark_id) & \\\n",
    "        (df_final[\"optimizer_id\"].str.contains(\"bbob_2d\") | \\\n",
    "         df_final[\"optimizer_id\"].str.contains(\"Default\") | \\\n",
    "         df_final[\"optimizer_id\"].str.contains(\"SAWEI\")\n",
    "         )\n",
    "    ]\n",
    "    df_bench = sort_df_by_mean(df_bench, key_performance=key_performance)\n",
    "    ax = sns.boxplot(\n",
    "        data=df_bench, x=key_performance, y=\"optimizer_id\", hue=\"optimizer_id\",\n",
    "        palette=color_palette, ax=ax, showfliers=False)\n",
    "\n",
    "    yticklabels = ax.get_yticklabels()\n",
    "    ax.set_title(benchmark_id)\n",
    "    ax.set_xlabel(\"Log Regret\")\n",
    "    ylabel = \"Optimizer\" if i == 0 else None\n",
    "    ax.set_ylabel(ylabel)\n",
    "    # ax.axvline(floor, linestyle=\"--\", linewidth=2, color=\"gray\")\n",
    "fig.tight_layout()\n",
    "savefig(fig, \"figures/results_icml/perf_per_benchmark_boxplot\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a23880c",
   "metadata": {},
   "source": [
    "# SAWEI-P on Mixed / YAHPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780b3407",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from carps.analysis.utils import savefig, setup_seaborn\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "setup_seaborn()\n",
    "\n",
    "# logs = pd.read_parquet(Path(result_dir) / logsprocessed_fn)\n",
    "# logs_cfg = pd.read_parquet(Path(result_dir) / logsprocessed_cfg_fn)\n",
    "df_final = pd.read_parquet(Path(result_dir) / df_final_processed_fn)\n",
    "df_final.loc[df_final[\"optimizer_id\"] == \"NoOpPolicy\", \"optimizer_id\"] = \"DefaultPolicy\"\n",
    "df_final = df_final[df_final[\"optimizer_id\"].isin([\"DefaultPolicy\", \"SAWEI-P\"])]\n",
    "\n",
    "for benchmark_id, gdf in df_final.groupby(\"benchmark_id\"):\n",
    "    print(benchmark_id)\n",
    "    sns.boxplot(data=gdf, x=\"optimizer_id\", y=\"log_regret\", hue=\"optimizer_id\")\n",
    "    plt.show()\n",
    "    sns.barplot(data=gdf, x=\"optimizer_id\", y=\"log_regret\", hue=\"optimizer_id\")\n",
    "    plt.show()\n",
    "    grid = sns.FacetGrid(data=gdf, col=\"task_id\", hue=\"optimizer_id\", col_wrap=5, sharex=True, sharey=False)\n",
    "    grid.map_dataframe(sns.boxplot, x=\"optimizer_id\", y=\"log_regret\")\n",
    "    grid.figure.suptitle(benchmark_id)\n",
    "    grid.add_legend()\n",
    "    grid.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
